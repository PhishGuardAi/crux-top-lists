name: Update Data Repo
on:
  workflow_call:
  workflow_dispatch:
jobs:
  download-bigquery-agg:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # Extended timeout for larger dataset
    steps:
      - id: "checkout"
        uses: "actions/checkout@v3"
        with:
          lfs: true  # Enable Git LFS for large files
      - id: "git-config"
        run: |
          git config --global http.postBuffer 524288000
          git config --global core.compression 9
          git config --global http.lowSpeedLimit 1000
          git config --global http.lowSpeedTime 300
      - id: "python"
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip"
      - id: "pip"
        run: pip install .
      - id: "auth"
        name: "Authenticate to Google Cloud"
        uses: "google-github-actions/auth@v1"
        with:
          credentials_json: ${{ secrets.bq }}
      - id: "download"
        run: "python3 -m cruxdownloader data"
      - id: "commit"
        name: Commit and push if it changed
        run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add data/*
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
